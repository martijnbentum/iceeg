import bad_epoch
import check_artifact_length as cal
import copy
import experiment as e
from lxml import etree
# from matplotlib import pyplot as plt
import numpy as np
import os
import path
import progressbar as pb
import random
import time
import windower

class xml_cnn:
	'''Load all predictions generated by the cnn and link them to the snippet indices of a window object.
	write bad epoch xml to ARTIFACT_DATA_ALL_PP folder.
	IMPORTANT: block start sample are the sample numbers in sf1000, snippet indices are in sf100
	bad epoch st and et sample are in sf 1000 WIP
	'''
	def __init__(self,b=None,cnn_model_name = 'rep-3_perc-50_fold-2_part-90',save_dir = None,bad_epochs = [],filename = '', load_predictions = True):
		'''Writes artifact info generated with manual_artifact_coder to xml files

		w 			windower object
		cnn_model.. name of the cnn model that generated the predictions
		save_dir 	directory to save data 
		bad_epochs 	a list of bad_epoch objects, can be empty
		filename 	xml filename, for loading or writing
		'''
		self.b=b 
		self.cnn_model_name = cnn_model_name
		if save_dir == None: self.save_dir = path.artifact_cnn_xml
		elif not os.path.isdir(save_dir):
			print('Could not locate:',save_dir,'using default:',path.artifact_cnn_xml)
			self.save_dir = path.artifact_cnn_xml
		else : self.save_dir = save_dir
		if self.b !=None:
			self.w = windower.Windower(b,sf = 100)
			self.name = windower.make_name(self.b)
			self.filename = make_filename(self.w,self.cnn_model_name)
			if load_predictions: self.load_predictions()
			else: self.loaded = False
			if self.loaded: self.set_indices()
		else:
			self.bad_epochs = bad_epochs
			self.filename = filename
			self.nclean_indices = 'NA'
			self.nartifact_indices = 'NA'
		# self.make_index_info()
		self.cnn_result = etree.Element('artifacts')


	def __str__(self):
		return etree.tostring(self.cnn_result, pretty_print=True).decode()

	def __repr__(self):
		if self.loaded:
			return 'xml_cnn-object: ' + self.name + '\tartifacts: ' +str(self.nartifact_indices) + '\tartifact_perc: ' + str(round(self.nartifact_indices / (self.nartifact_indices +self.pred_class.shape[0]),3)) + '\tmodel: ' + str(self.cnn_model_name)
		else:
			return 'xml_cnn-object: ' + self.name + '\tartifacts: NA\tartifact_perc: NA\tmodel: NA'


	def print_info(self):
		if len(self.artefacts) > 0: self.calc_clean_artifact_samples()
		if not hasattr(self,'artefact_samples'):
			print('cannot compute percentage artefact')
			return -1
		print('nartefact samples: ',self.artefact_samples)
		print('nclean_samples: ',self.clean_samples)
		print('perc_artefact: ',self.artefact_samples_perc)
			

	def load_predictions(self):
		'''Load np matrices rows: number of snippets, columns: clean -artifact (one-hot).'''
		try:
			self.pred_class = np.load(path.snippet_annotation+ self.cnn_model_name + '_' + self.w.name + '_class.npy')
			self.pred_class_adj = np.load(path.snippet_annotation+ self.cnn_model_name + '_' +self.w.name + '_class-adj.npy')
			self.pred_perc = np.load(path.snippet_annotation+ self.cnn_model_name + '_' +self.w.name + '_perc.npy')
			self.loaded = True
		except:
			print('could not load files,only found the following files:',glob.glob(path.snippet_annotation + self.cnn_model_name + '_' + self.w.name + '*'))
			self.loaded = False


	def set_indices(self):
		'''Set indices (=snippets) to clean or artifact.'''
		self.clean_indices = np.where(self.pred_class == 0)[0]
		self.clean_indices_adj = np.where(self.pred_class_adj == 0)[0]

		self.artifact_indices = np.where(self.pred_class == 1)[0]
		self.artifact_indices_adj = np.where(self.pred_class_adj == 1)[0]

		self.nclean_indices = len(self.clean_indices)
		self.nclean_indices_adj = len(self.clean_indices_adj)
		self.nartifact_indices = len(self.artifact_indices)
		self.nartifact_indices_adj = len(self.artifact_indices_adj)


	def make_bad_epochs(self,minimal_duration = 2000):
		'''Create a list of bad epochs from xml file.'''
		self.bad_epochs = []
		ws = self.w.windows['sf1000']
		previous_annotation = ''
		perc_clean = []
		for index in range(self.pred_class.shape[0]):
			annotation = 'clean' if self.pred_class_adj[index] == 0 else 'artifact'
			perc_clean.append(  self.pred_perc[index][0] )
			if previous_annotation == '': 
				# first index
				st_sample =  ws.start_snippets[index]
				previous_annotation = annotation

			elif previous_annotation != annotation or index == self.pred_class.shape[0] - 1:
				# start of a new bad epoch, handle creation previous bad epoch
				b = self.b
				if index == self.pred_class.shape[0] - 1: 
					if b.start_marker_missing or b.end_marker_missing: et_sample = self.pred_class.shape[0] * 10
					else: et_sample = b.duration_sample
				else: et_sample =  (ws.start_snippets[index-1] + ws.end_snippets[index-1]) /2
				start = bad_epoch.Boundary(x = int(st_sample),boundary_type='start',visible = False)
				end = bad_epoch.Boundary(x = int(et_sample),boundary_type='end',visible = False)
				epoch_id = get_cnn_epoch_id(increment = True)
				perc_clean_last = perc_clean.pop(-1)
				perc_clean = ' '.join([str(np.mean(np.array(perc_clean))),str(np.std(np.array(perc_clean)))])

				# create bad epoch
				be = bad_epoch.Bad_epoch(start_boundary = start, end_boundary = end, annotation = previous_annotation ,pp_id = b.pp_id, exp_type = b.exp_type, bid = b.bid,block_st_sample = b.st_sample,epoch_id = epoch_id,coder = self.cnn_model_name, correct = 'unk',visible = False ,perc_clean = perc_clean)

				self.bad_epochs.append(be)
				st_sample = et_sample + 1 
				previous_annotation = annotation
				perc_clean = [perc_clean_last]
		if len(self.bad_epochs) > 1: self.combine_bad_epochs(minimal_duration)
		else: self.artifacts = copy.deepcopy(self.bad_epochs)
			
		self.calc_clean_artifact_samples()
		self.artifacts2indices()


	def calc_clean_artifact_samples(self):
		'''calculate the number of clean and artifact samples.'''
		self.artefact_samples,self.clean_samples = 0,0
		for be in self.artifacts:
			if be.annotation == 'artifact': self.artefact_samples += be.duration
			else: self.clean_samples += be.duration
		self.artefact_samples_perc = self.artefact_samples / (self.artefact_samples + self.clean_samples)


	def combine_bad_epochs(self,minimal_duration = 2000):
		'''Combine bad_epochs into the format used for artifact clean files. 
		Clean sections should at least be a second long.'''
		self.temp_artifacts  = [be for be in self.bad_epochs if be.annotation == 'artifact']
		self.stiches = cal.stitch_artifacts(self.temp_artifacts,minimal_duration) #minimal nsamples for clean artifact 
		self.stiched_stiches = cal.stitch_stiches(self.stiches)
		self.artifacts = cal.combine_artifacts(self.temp_artifacts,self.stiched_stiches)
		cal.check_artifacts(self.artifacts,self.b.fid2ort,'clean',minimal_duration = minimal_duration)

	def artifacts2indices(self):
		print('finding snippets that overlap with current artifacts annotation (resulting xml file)')
		bar = pb.ProgressBar()
		bar(range(len(self.artifacts)))
		snips = self.w.windows['sf1000']
		starts, ends = snips.start_snippets[:self.pred_class_adj.shape[0]], snips.end_snippets[:self.pred_class_adj.shape[0]]
		self.artifacts_class = np.zeros(self.pred_class.shape)
		for u,a in enumerate(self.artifacts):
			index = []
			bar.update(u)
			indices, overlap = windower.find_snippet_index_and_overlap_bad_epoch(starts,ends,a)
			for i,o in enumerate(overlap):
				if o >= .5:
					index.append(indices[i])
			if a.annotation == 'artifact': self.artifacts_class[index] = 1
			if a.annotation == 'clean':
				a.perc_clean = ' '.join([str(np.mean(self.pred_perc[index,0])),str(np.std(self.pred_perc[index,0]))])
		


	def bad_epochs2xml(self):
		'''Create xml file from bad_epochs, adapted from xml_handler, '''
		self.cnn_result = etree.Element('artifacts')
		for be in self.artifacts:
			if not be.ok:
				pass
			if type(be.epoch_id) == list: be.epoch_id = '_'.join(be.epoch_id)
			be_xml = etree.SubElement(self.cnn_result, 'bad_epoch', id = str(be.epoch_id))
			# set epoch info elements
			elements = 'st_sample,et_sample,duration,block_st_sample,pp_id,exp_type,bid,color,coder,correct,annotation,note,correct,corrector,perc_clean'.split(',')
			for e in elements:
				element = etree.SubElement(be_xml, e)
				if hasattr(be,e):
					element.text = str(getattr(be,e))
				else:
					element.text = 'NA'


	def xml2bad_epochs(self):
		'''Create a list of bad epochs from xml file.'''
		self.artifacts= []
		# print('Starting with list of',len(self.artifacts),' bad epochs')
		for be_xml in self.cnn_result.iter('bad_epoch'):
			# fetch subelements
			element_names = 'st_sample,et_sample,block_st_sample,pp_id,bid,annotation,color,exp_type,coder,note,correct,corrector,perc_clean'.split(',')
			element_values = []
			for e in element_names:
				if be_xml.find(e) != None:
					element_values.append(be_xml.find(e).text)
				else:
					element_values.append('NA')
			st_sample,et_sample,block_st_sample,pp_id,bid,annotation,color,exp_type,coder,note,correct,corrector,perc_clean= element_values
			epoch_id = be_xml.attrib['id']
			#create start and end boundary
			start = bad_epoch.Boundary(x = int(st_sample),boundary_type='start',visible = False)
			end = bad_epoch.Boundary(x = int(et_sample),boundary_type='end',visible = False)
			# create bad epoch
			be = bad_epoch.Bad_epoch(start_boundary = start, end_boundary = end, annotation = annotation, color = color,pp_id = pp_id, exp_type = exp_type, bid = bid,block_st_sample = block_st_sample,epoch_id = epoch_id, visible = False ,correct = correct,perc_clean = perc_clean, coder = self.cnn_model_name)
			self.artifacts.append(be)
		# print('N bad epoch:',len(self.artifacts),'artifacts')
		return self.artifacts


	def make_time(self):
		self.cdate = time.time()
		self.date = time.strftime("%b-%d-%Y-%H-%M-%S", time.localtime(self.cdate))


	def write_update(self):
		'''Writes data to xml file and moves a copy of the previous version to folder OLD'''
		self.make_time()
		if os.path.isfile(self.filename): 
			print('moving file:','mv ' + self.filename +  ' ' + path.artifact_data_all_pp + 'OLD/' + self.filename.split('/')[-1].strip('.xml') + '_'+self.date + '.xml')
			os.system('mv ' + self.filename +  ' ' + path.artifacts + 'OLD/' + self.filename.split('/')[-1].rstrip('.xml') + '_'+self.date + '.xml')
		fout = open(self.filename,'w')
		fout.write(etree.tostring(self.artifacts, pretty_print=True).decode())
		fout.close()


	def write(self):
		'''Save xml with index info and selection object to ARTIFACT_DATA_ALL_PP.'''
		fout = open(self.filename,'w')
		fout.write(etree.tostring(self.cnn_result, pretty_print=True).decode())
		fout.close()

	def read(self):
		'''Read index info and selection xml into object.'''
		self.cnn_result = etree.fromstring(open(self.filename).read())

	def load(self):
		self.read()
		self.xml2bad_epochs()
		self.calc_clean_artifact_samples()

	def artifact_start_duration(self, minimal_artifact_duration = 200):
		'''return a list of onsets and durtion in seconds for each artifact in artifacts.'''
		onsets = [] 
		durations = []
		for a in self.artifacts:
			if a.annotation == 'artifact' and a.duration >= minimal_artifact_duration:
				onsets.append(a.st_sample / 1000)
				durations.append(a.duration / 1000)
		return onsets, durations
				
'''
	def plot(self):
		plt.figure()
		plt.plot(self.pred_class_adj)
		plt.plot(self.pred_perc[:,0],alpha = .3)
		plt.plot(self.artifacts_class,linewidth = 5, alpha = .5 )
		plt.legend(('pred class','pred perc','annot artifacts'))
'''

	
def make_filename(w, model_name):
	return path.artifact_cnn_xml + model_name + '_' + w.name+ '.xml'

def get_cnn_epoch_id(increment = False):
	'''Read and optionally increment cnn epoch id for the bad epoch generated based on cnn predictions.'''
	n = int(open(path.data +'cnn_epoch_id').read())
	if increment:
		fout = open(path.data + 'cnn_epoch_id','w')
		fout.write(str(n+1))
		fout.close()
	return n

def make_xml_all_pp(fo, minimal_duration = 2000, start_index = 0, exp = None):
	xml = []
	missing_data_blocks = []
	if exp == None:
		exp = e.Experiment()
		exp.add_all_participants(fid2ort = fo)
		exp.add_all_sessions()
	for i,b in enumerate(exp.blocks[start_index:]):
		print(i,b.pp_id,b.exp_type,b.bid)
		n = windower.make_name(b)
		if not os.path.isfile(path.eeg100hz + n + '.npy'): 
			print(path.eeg100hz + n + '.npy', 'file not found.')
			missing_data_blocks.append(b)
			continue
		x = xml_cnn(b)
		if x.loaded:
			x.make_bad_epochs(minimal_duration)
			x.bad_epochs2xml()
			x.write()
			xml.append(x)
		else: print('No xml file for:\n',b)
	return xml
	

