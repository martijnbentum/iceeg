import bad_channel
from bad_epoch import Boundary
import check_artifact_channel_length as cacl
import copy
import experiment as e
import glob
from lxml import etree
import numpy as np
import os
import path
import progressbar as pb
import random
import time
import utils
import windower

# adapted from xml_cnn


class xml_ch_cnn:
	'''Load all predictions generated by the cnn and link them to the snippet indices of a window object.
	'''
	def __init__(self,b=None,cnn_ch_model_name = 'rep-26_perc-20_fold-1_part-70_kernel-6_model7',save_dir = None,bad_channels= [],filename = '', load_predictions = True,use_adjusted_prediction = False,minimal_clean_duration = 2000, minimal_artifact_duration = 1000):
		'''Writes artifact info generated with manual_artifact_coder to xml files

		b 			block object
		cnn_model.. name of the cnn model that generated the predictions
		save_dir 	directory to save data 
		bad_chan... a list of bad_channel objects, can be empty
		filename 	xml filename, for loading or writing
		'''
		self.b=b 
		self.cnn_ch_model_name = cnn_ch_model_name
		self.ch_names = utils.load_selection_ch_names()
		self.use_adjusted_prediction = use_adjusted_prediction
		self.minimal_artifact_duration = minimal_artifact_duration
		self.minimal_clean_duration = minimal_clean_duration
		if save_dir == None: self.save_dir = path.artifact_ch_cnn_xml
		elif not os.path.isdir(save_dir):
			print('Could not locate:',save_dir,'using default:',path.artifact_ch_cnn_xml)
			self.save_dir = path.artifact_ch_cnn_xml
		else : self.save_dir = save_dir
		if self.b !=None:
			self.w = windower.Windower(b,sf = 100)
			self.name = windower.make_name(self.b)
			self.filename = make_filename(self.w,self.cnn_ch_model_name)
			if load_predictions: self.load_predictions()
			else: self.loaded = False
			if self.loaded: self.set_indices()
		else:
			self.bad_channels= bad_channels
			self.filename = filename
			self.nclean_indices = 'NA'
			self.nartifact_indices = 'NA'
		# self.make_index_info()
		self.cnn_result = etree.Element('artifacts')


	def __str__(self):
		return etree.tostring(self.cnn_result, pretty_print=True).decode()

	def __repr__(self):
		if self.loaded:
			m = 'xml_ch_cnn-object: ' + self.name 
			m += '\tartifacts: ' + str(self.nartifact_indices)
			m += '\tartifact_perc: ' + str(round(self.nartifact_indices /
				int(self.pred_class.size) ,3)) 
			m += '\tmodel: ' + str(self.cnn_ch_model_name)
			return m
		else:
			m = 'xml_ch_cnn-object: ' + self.name 
			m += '\tartifacts: NA\tartifact_perc: NA\tmodel: NA'
			return m


	def print_info(self):
		if len(self.artefacts) > 0: self.calc_clean_artifact_samples()
		if not hasattr(self,'artefact_samples'):
			print('cannot compute percentage artefact')
			return -1
		print('nartefact samples: ',self.artefact_samples)
		print('nclean_samples: ',self.clean_samples)
		print('perc_artefact: ',self.artefact_samples_perc)
			

	def load_predictions(self):
		'''Load np matrices rows: number of snippets, columns: nchannels'''
		f=path.channel_snippet_annotation+ self.cnn_ch_model_name + '_' + self.w.name 
		self.pred_class_filename = f + '_class.npy'
		self.pred_class_adj_filename = f + '_class-adj.npy'
		self.pred_perc_filename = f + '_perc.npy'
		try:
			self.pred_class = np.load(self.pred_class_filename)
			if self.use_adjusted_prediction:
				self.pred_class_adj = np.load(self.pred_class_adj_filename)
			self.pred_perc = np.load(self.pred_perc_filename)
			self.loaded = True
		except:
			m = 'could not load files,only find the following files:'
			m += '\n'.join(glob.glob(f + '*')) + '\n'
			print(m)
			self.loaded = False


	def set_indices(self):
		'''Set indices (=snippets) to clean or artifact.'''
		self.ch2artifact_indices = {}
		self.ch2clean_indices = {}
		for i,ch in enumerate(self.ch_names):
			if self.use_adjusted_prediction:
				ci = np.array(np.where(self.pred_class_adj[:,i] == 0)).transpose()
				ai = np.array(np.where(self.pred_class_adj[:,i] == 1)).transpose()
			else:
				ci = np.array(np.where(self.pred_class[:,i] == 0)).transpose()
				ai = np.array(np.where(self.pred_class[:,i] == 1)).transpose()
			self.ch2clean_indices[ch] = ci 
			self.ch2artifact_indices[ch] = ai

		if self.use_adjusted_prediction:
			self.nartifact_indices = np.sum(self.pred_class_adj)
			self.nclean_indices = self.pred_class_adj.size - self.nartifact_indices
		else:
			self.nartifact_indices = np.sum(self.pred_class)
			self.nclean_indices = self.pred_class.size - self.nartifact_indices


	def make_bad_channel(self,channel_index, minimal_duration = None):
		if minimal_duration == None: minimal_duration = self.minimal_clean_duration
		ws = self.w.windows['sf1000']
		previous_annotation = ''
		perc_clean = []
		bad_channels = []
		name = self.ch_names[channel_index]
		for sample_index in range(self.pred_class.shape[0]):
			annotation = 'clean' if self.pred_class[sample_index,channel_index] == 0 else 'artifact'
			perc_clean.append(  self.pred_perc[sample_index,channel_index])
			if previous_annotation == '': 
				# first index
				st_sample =  ws.start_snippets[sample_index]
				previous_annotation = annotation

			elif previous_annotation != annotation or sample_index == self.pred_class.shape[0] - 1:
				# start of a new bad channel, handle creation previous bad channel 
				b = self.b
				if sample_index == self.pred_class.shape[0] - 1: 
					# last sample of block
					if b.start_marker_missing or b.end_marker_missing: 
						et_sample = self.pred_class.shape[0] * 10
					else: et_sample = b.duration_sample

				else: 
					# the start/end of bad_channel is half way between start/end sample index
					et_sample = (ws.start_snippets[sample_index-1] + 
						ws.end_snippets[sample_index-1]) /2
				start = Boundary(x = int(st_sample),boundary_type='start',visible = False)
				end = Boundary(x = int(et_sample),boundary_type='end',visible = False)
				epoch_id = get_cnn_ch_epoch_id(increment = True)
				perc_clean_last = perc_clean.pop(-1)
				perc_clean = ' '.join([str(np.mean(np.array(perc_clean))),
					str(np.std(np.array(perc_clean)))])

				# create bad channel 
				bc = bad_channel.Bad_channel(channel = name,start_boundary = start, end_boundary = end, annotation = previous_annotation ,pp_id = b.pp_id, exp_type = b.exp_type, bid = b.bid,block_st_sample = b.st_sample,epoch_id = epoch_id,coder = self.cnn_ch_model_name, correct = 'unk',visible = False ,perc_clean = perc_clean)

				self.bad_channels[name].append(bc)
				st_sample = et_sample + 1 
				previous_annotation = annotation
				perc_clean = [perc_clean_last]

		if len(self.bad_channels[name]) > 1: 
			self.combine_bad_channels(channel_index, minimal_duration)
		else: self.artifacts.extend(copy.deepcopy(self.bad_channels[name]))
		# self.artifacts.extend(copy.deepcopy(self.bad_channels[name]))


	def make_bad_channels(self,minimal_duration = None):
		'''Create a list of bad epochs from xml file.'''
		if minimal_duration == None: minimal_duration = self.minimal_clean_duration
		self.bad_channels= {}
		for name in self.ch_names:
			self.bad_channels[name] = [] 
		self.artifacts = []

		bar = pb.ProgressBar()
		bar(range(len(self.ch_names)))
		for index in range(len(self.ch_names)):
			bar.update(index)
			self.make_bad_channel(channel_index=index, minimal_duration= minimal_duration)

		self.calc_clean_artifact_samples()
		# self.artifacts2indices()


	def calc_clean_artifact_samples(self):
		'''calculate the number of clean and artifact samples.'''
		self.artefact_samples,self.clean_samples = 0,0
		for bc in self.artifacts:
			if bc.annotation == 'artifact': self.artefact_samples += bc.duration
			else: self.clean_samples += bc.duration
		self.artefact_samples_perc = (self.artefact_samples / 
			(self.artefact_samples + self.clean_samples))


	def combine_bad_channels(self,channel_index,minimal_duration = None):
		'''Combine bad_channels into the format used for artifact clean files. 
		Clean sections should at least be minimal duration long.
		bad channels are combined on channel level'''
		if minimal_duration == None: minimal_duration = self.minimal_clean_duration

		name = self.ch_names[channel_index]
		temp_artifacts  = [bc for bc in self.bad_channels[name] if bc.annotation == 'artifact']

		#minimal nsamples for clean artifact 
		self.stiches = cacl.stitch_artifacts(temp_artifacts,minimal_duration) 

		self.stiched_stiches = cacl.stitch_stiches(self.stiches)
		temp_artifacts =  cacl.combine_artifacts(temp_artifacts,self.stiched_stiches)
		cacl.check_artifacts(artifacts=temp_artifacts,b = self.b,default='clean',minimal_duration = minimal_duration)
		self.artifacts.extend(temp_artifacts)


	def artifacts2indices(self):
		'''Adds perc clean to artifact, but I think this already happens when they are created'''
		print('finding snippets that overlap with current artifacts annotation (resulting xml file)')
		bar = pb.ProgressBar()
		bar(range(len(self.artifacts)))
		snips = self.w.windows['sf1000']
		if self.use_adjusted_prediction:
			starts, ends = snips.start_snippets[:self.pred_class_adj.shape[0]], snips.end_snippets[:self.pred_class_adj.shape[0]]
		else:
			starts, ends = snips.start_snippets[:self.pred_class.shape[0]], snips.end_snippets[:self.pred_class.shape[0]]
		self.artifacts_class = np.zeros(self.pred_class.shape)
		for u,a in enumerate(self.artifacts):
			index = []
			bar.update(u)
			indices, overlap = windower.find_snippet_index_and_overlap_bad_epoch(starts,ends,a)
			for i,o in enumerate(overlap):
				if o >= .5:
					index.append(indices[i])
			if a.annotation == 'artifact': self.artifacts_class[index] = 1
			if a.annotation == 'clean':
				a.perc_clean = ' '.join([str(np.mean(self.pred_perc[index,0])),str(np.std(self.pred_perc[index,0]))])
		


	def bad_channel2xml(self):
		'''Create xml file from bad_epochs, adapted from xml_handler, '''
		self.cnn_result = etree.Element('artifacts')
		self.short_artifacts = []
		self.xml_artifacts = []
		for bc in self.artifacts:
			if not bc.ok or bc.annotation == 'clean' or bc.duration < self.minimal_artifact_duration:
				if bc.duration < self.minimal_artifact_duration: self.short_artifacts.append(bc)
				continue
			if type(bc.epoch_id) == list: bc.epoch_id = '_'.join(bc.epoch_id)
			bc_xml = etree.SubElement(self.cnn_result, 'bad_channel', id = str(bc.epoch_id))
			# set epoch info elements
			elements = 'channel,st_sample,et_sample,duration,block_st_sample,pp_id,exp_type,bid,color,coder,correct,annotation,note,correct,corrector,perc_clean'.split(',')
			for e in elements:
				element = etree.SubElement(bc_xml, e)
				if hasattr(bc,e):
					element.text = str(getattr(bc,e))
				else:
					element.text = 'NA'
			self.xml_artifacts.append(bc)


	def xml2bad_channel(self):
		'''Create a list of bad epochs from xml file.'''
		self.artifacts= []
		# print('Starting with list of',len(self.artifacts),' bad epochs')
		for bc_xml in self.cnn_result.iter('bad_channel'):
			# fetch subelements
			element_names = 'channel,st_sample,et_sample,block_st_sample,pp_id,bid,annotation,color,exp_type,coder,note,correct,corrector,perc_clean'.split(',')
			element_values = []
			for e in element_names:
				if bc_xml.find(e) != None:
					element_values.append(bc_xml.find(e).text)
				else:
					element_values.append('NA')
			channel,st_sample,et_sample,block_st_sample,pp_id,bid,annotation,color,exp_type,coder,note,correct,corrector,perc_clean= element_values
			epoch_id = bc_xml.attrib['id']
			#create start and end boundary
			start = Boundary(x = int(st_sample),boundary_type='start',visible = False)
			end = Boundary(x = int(et_sample),boundary_type='end',visible = False)
			# create bad epoch
			bc = bad_channel.Bad_channel(channel = channel,start_boundary = start, end_boundary = end, annotation = annotation, color = color,pp_id = pp_id, exp_type = exp_type, bid = bid,block_st_sample = block_st_sample,epoch_id = epoch_id, visible = False ,correct = correct,perc_clean = perc_clean, coder = self.cnn_ch_model_name)
			self.artifacts.append(bc)
		# print('N bad epoch:',len(self.artifacts),'artifacts')
		return self.artifacts


	def make_time(self):
		self.cdate = time.time()
		self.date = time.strftime("%b-%d-%Y-%H-%M-%S", time.localtime(self.cdate))


	def write_update(self):
		'''Writes data to xml file and moves a copy of the previous version to folder OLD'''
		self.make_time()
		if os.path.isfile(self.filename): 
			print('moving file:','mv ' + self.filename +  ' ' + path.artifact_data_all_pp + 'OLD/' + self.filename.split('/')[-1].strip('.xml') + '_'+self.date + '.xml')
			os.system('mv ' + self.filename +  ' ' + path.artifacts + 'OLD/' + self.filename.split('/')[-1].rstrip('.xml') + '_'+self.date + '.xml')
		fout = open(self.filename,'w')
		fout.write(etree.tostring(self.artifacts, pretty_print=True).decode())
		fout.close()


	def write(self):
		'''Save xml with index info and selection object to ARTIFACT_DATA_ALL_PP.'''
		fout = open(self.filename,'w')
		fout.write(etree.tostring(self.cnn_result, pretty_print=True).decode())
		fout.close()

	def read(self):
		'''Read index info and selection xml into object.'''
		self.cnn_result = etree.fromstring(open(self.filename).read())

	def load(self):
		self.read()
		self.xml2bad_channel()
		self.calc_clean_artifact_samples()

	def artifact_start_duration(self, minimal_artifact_duration = None):
		'''return a list of onsets and durtion in seconds for each artifact in artifacts.'''
		if minimal_artifact_duration == None: minimal_artifact_duration = self.minimal_artifact_duration
		onsets = [] 
		durations = []
		for a in self.artifacts:
			if a.annotation == 'artifact' and a.duration >= minimal_artifact_duration:
				onsets.append(a.st_sample / 1000)
				durations.append(a.duration / 1000)
		return onsets, durations
				

	
def make_filename(w, model_name):
	return path.artifact_ch_cnn_xml + model_name + '_' + w.name+ '.xml'

def get_cnn_ch_epoch_id(increment = False):
	'''Read and optionally increment cnn epoch id for the bad epoch generated based on cnn predictions.'''
	n = int(open(path.data +'cnn_ch_epoch_id').read())
	if increment:
		fout = open(path.data + 'cnn_ch_epoch_id','w')
		fout.write(str(n+1))
		fout.close()
	return n

def load_exp(fo):
	exp = e.Experiment()
	exp.add_all_participants(fid2ort = fo)
	exp.add_all_sessions()
	return exp

def make_xml_all_pp(fo, minimal_clean_duration = 2000,minimal_artifact_duration = 1000, start_index = 0, exp = None):
	xml = []
	missing_data_blocks = []
	xml_not_loaded_blocks = []
	if exp == None: exp = load_exp(fo)
	for i,b in enumerate(exp.blocks[start_index:]):
		print(i,b.pp_id,b.exp_type,b.bid)
		n = windower.make_name(b)
		if not os.path.isfile(path.eeg100hz + n + '.npy'): 
			print(path.eeg100hz + n + '.npy', 'file not found.')
			missing_data_blocks.append(b)
			continue
		x = xml_ch_cnn(b,minimal_clean_duration = minimal_clean_duration,minimal_artifact_duration=minimal_artifact_duration)
		if x.loaded:
			x.make_bad_channels()
			x.bad_channel2xml()
			x.write()
			xml.append(x)
		else: 
			print('No xml file for:\n',b)
			xml_not_loaded_blocks.append(b)
	return xml, missing_data_blocks, xnlb,exp
	

