import copy
import cnn_channel_data
import cnn_ch_output_data as ccod
import load_all_ort
import glob
import model_ch_cnn
import model_ch_cnn_output as mcco
import numpy as np
import path
import sklearn.metrics
import tensorflow as tf
import utils
import windower

class classify_channel_artifact:
	'''Classify the artifacts and clean channels of an eeg block.
	Classification can be based on model_ch_cnn_name and can be adjusted with mcco 
	mcco is a simple linear regression model to prune false positive from the 
	mcc model. The mcco model sees only predicted artifacts and preceding en superceding
	classification (values 0-1) and removes false positives.
	'''
	def __init__(self,name = None,block = None,model_ch_cnn_name = 'test_perc-comparison_perc-25_fold-1_part-70_kernel-6_model7' , mcco_name = 'cnn_output_model_wl-201_perc-93',fo = None,make_adj_pred = False):
		tf.reset_default_graph()
		self.fo = fo
		if not self.set_block_name(block,name): return None
		self.model_ch_cnn_name = model_ch_cnn_name
		self.mcco_name = mcco_name
		if make_adj_pred:
			self.load_predicted()
			self.generate_predicted_adj()



	def __str__(self):
		m = 'name:\t\t\t' + str(self.name) + '\n'
		m += 'model_ch_cnn_name:\t' + str(self.model_ch_cnn_name) + '\n'
		m += 'mcco:\t\t\t' + str(self.mcco_name) + '\n'
		if hasattr(self,'predicted') and isinstance(self.predicted,np.ndarray): m += 'predicted:\t\tavailable\n'
		else: m += 'predicted:\t\tNA\n'
		if hasattr(self,'predicted_adj') and isinstance(self.predicted_adj,np.ndarray): m += 'predicted_adj:\t\tavailable\n'
		else: m += 'predicted_adj:\t\tNA\n'
		if hasattr(self,'predicted_perc') and isinstance(self.predicted_perc,np.ndarray): m += 'predicted_perc:\t\tavailable\n'
		else: m += 'predicted_perc:\t\tNA\n'
		return m


	def __repr__(self):
		return 'classify-ch-artifact: ' +self.name.replace('_',' ')


	def load_predicted(self):
		'''Load artifact classifications.'''
		self.do = ccod.cnn_ch_output2data(name= self.name, model_name = self.model_ch_cnn_name)
		self.predicted = self.do.predicted


	def generate_predicted(self, clean_up = True, save = True,load_model = True,load_predicted = False):
		'''Classify eeg data on artifacts.'''
		d = cnn_channel_data.cnn_data(1) # fold 1 was used for training, 10 fold training and testing was computationally to expensive
		if load_model or not hasattr(self,'m'):
			self.m = model_ch_cnn.load_model(path.model_channel + self.model_ch_cnn_name,d)
		self.predicted_class, self.predicted_perc = self.m.predict_block(self.block, save = save)
		if load_predicted:
			self.load_predicted()
		if clean_up:
			self.m.clean_up()


	def generate_predicted_adj(self, identifier = '', save = True):
		'''Adjust predicted channel artifacts generated by model_ch_cnn with mcco model.
		compare with ground truth if available.
		the cnn_ch_output_data object contains a list (predicted_artifact_data) with
		an np array for each channel with shape (npredicted_artifactsXwindow_length)
		a second list (predicted_artifact_indices) contains 1d nparrays with shape
		npredicted artifacts.
		feed each np array in the data list to the mcco model and put the output at the
		indices contained in the np array in the indices list
		'''
		# copy original prediction based on the mcc model into adjusted variable
		self.predicted_adj = copy.copy(self.do.pc)
		# create a list to store adjusted predictions
		self.predicted_artifact_adj = []

		if len(self.do.predicted_artifact_data) == self.do.nchannels and self.do.n_artifact >0:
			self.mo = mcco.load_model(path.channel_cnn_output_data + self.mcco_name,self.do)
			# for each channel compute adjusted prediction (prunning the false positives)
			for i,channel in enumerate(self.do.predicted_artifact_data):
				self.predicted_artifact_adj.append( self.mo.compute_prediction_class(data=channel) )
				self.predicted_adj[self.do.predicted_artifact_indices[i],i] = self.predicted_artifact_adj[-1]
			self.mo.clean_up()

		if not isinstance(self.do.ground_truth,np.ndarray): self.confusion_matrix_adj = np.zeros((2,2))
		else: 
			self.flatten_gt = np.ravel(self.do.ground_truth,'F')
			self.flatten_pc_adj = np.ravel(self.predicted_adj,'F')
			# self.confusion_matrix_adj = np.zeros((2,2))
			self.confusion_matrix_adj = sklearn.metrics.confusion_matrix(self.flatten_gt,self.flatten_pc_adj)#, labels = [0,1])

		self.output_name = path.channel_snippet_annotation+ identifier + self.model_ch_cnn_name + '_' + self.name 
		self.eval_name = path.confusion_matrices + identifier + self.model_ch_cnn_name + '_' + self.name 
		if save:
			np.save(self.output_name + '_class-adj', self.predicted_adj)
			if isinstance(self.do.ground_truth, np.ndarray):
				np.save(self.eval_name+ '_cm', self.do.confusion_matrix)
				np.save(self.eval_name+ '_cm-adj', self.confusion_matrix_adj)
			else:print('no ground truth for',self.name)


	def set_block_name(self,block,name):
		'''Sets name and loads corresponding block object.'''
		if name == None and block == None:
			print('Please provide name or block object.')
			return False
		if name == None:
			self.name = windower.make_name(block)
			self.block = block
		if block == None:
			self.block = utils.name2block(name,self.fo)
			self.name = name
		return True


def get_names_output_files(model_name = 'rep-3_perc-50_fold-2_part-90'):
	'''Get the filenames of the perc files, which are output from a cnn model.

	model_name  	name of the cnn model to generate the output files.
	'''
	fn = glob.glob(path.channel_snippet_annotation + model_name + '_pp*class.npy')
	names = [f.split('part-90_')[-1].split('_class.npy')[0] for f in fn]
	return names

def get_names_manually_annotated():
	fn = glob.glob(path.channel_artifact_training_data + 'pp*exp*data.npy')
	names = [f.split('/')[-1].rstrip('_data.npy') for f in fn]
	print('found: ',len(names),' files')
	return names

def get_names_blocks():
	fn = glob.glob(path.eeg100hz + 'pp*.npy')
	names = [f.split('/')[-1].rstrip('.npy') for f in fn]
	print('found: ',len(names),' files')
	return names

def remove_present_names(names):
	output = []
	present_names = glob.glob(path.channel_snippet_annotation + '*')
	for name in names:
		found = False
		for present_name in present_names:
			if name in present_name:
				found = True
		if not found:
			output.append(name)
	print('nfiles to be classified:',len(output),'out of:',len(names),'total')
	return output

def generate_predictions_manually_annotated(model_ch_cnn_name = None,fo =None):
	'''Classify clean artifact for all blocks that are manually annotated.
	Predictions are save in the path.channel_snippet_annotation directory.'''
	if fo == None:
		fo = load_all_ort.load_fid2ort()
	names = get_names_manually_annotated()
	for i,name in enumerate(names):
		if model_ch_cnn_name != None:
			c = classify_channel_artifact(name =name,fo=fo,model_ch_cnn_name = model_ch_cnn_name)
			if i == 0: c.generate_predicted(clean_up = False)
			else: c.generate_predicted(clean_up = False,load_model=False)


def generate_predictions_all_blocks(model_ch_cnn_name = None,fo=None,skip_present = True):
	'''Classify clean artifact for all blocks 
	Predictions are save in the path.channel_snippet_annotation directory.

	model_ch_cnn_name 	 	name of the cnn artifact model
	fo 						object to faster load blocks see load_all_ort 
	skip_present 			skip files that are already classified and present the dir
	'''
	if fo == None:
		fo = load_all_ort.load_fid2ort()
	names = get_names_blocks()
	if skip_present: names = remove_present_names(names)
	for i,name in enumerate(names):
		if model_ch_cnn_name != None:
			c = classify_channel_artifact(name =name,fo=fo,model_ch_cnn_name = model_ch_cnn_name)
			if i == 0: c.generate_predicted()
			else: c.generate_predicted()

